# 2RP Net - Engenharia de Dados

<br/>

## üóÑ Ambiente de desenvolvimento e linguagens

<table>
  <tr>
  <th>Plataforma</th>
  <th>SQL</th>
  <th>Programa√ß√£o</th>
  </tr>
   <tr>
  <th><img src="https://cdn.freelogovectors.net/wp-content/uploads/2020/11/databricks-logo.png" width="100px;"> </th>
  <th><img src="https://d117h1jjiq768j.cloudfront.net/images/default-source/products/datadirect/dci-logos/spark-sql-logo.png?sfvrsn=97380b7f_2" width="100px;"></th>
  <th><img src="https://www.nobleprog.com.br/sites/hitrahr/files/category_images/height100_scale/pyspark_training.png?t=59415bb3" width="100px;"></th>
  </tr>
  </table>
  

 
> O Databricks foi escolhido devido ao suporte de diversas linguagens e servi√ßos em nuvem, tendo tamb√©m a possibilidade de ler dados de diversas fontes.
>  Assim como as ferramentas Spark que atendem a diversos volumes de dados.

<br/>


## üíª Pr√©-requisitos

>Antes de come√ßar, verifique se voc√™ seguiu aos seguintes requisitos:
* Fazer cadastro na plataforma <a href="https://databricks.com/try-databricks?itm_data=NavBar-TryDatabricks-Trial">`Databricks`</a>
* Ter baixado o notebook <a href="https://github.com/LucasGabriello/2RP/raw/main/2RP.dbc">`2RP.dbc`</a>
* Ter baixado e extraido arquivos .csv compactatos em <a href="https://github.com/LucasGabriello/2RP/raw/main/dados.zip">`dados.zip`</a>
### ou
```
gh repo clone LucasGabriello/2RP
```


## üöÄ Instalando 

### Instalando notebook

>Ja na tela inicial do Databricks clique no icone do Workspace

![img1](https://user-images.githubusercontent.com/22823453/154808436-ea41067d-05ee-42dc-a768-87f8d9133c0d.png)
<br/>

>Na aba Workspace clique no drop down e selecione a op√ß√£o Import

![img2](https://user-images.githubusercontent.com/22823453/154808478-defb2b08-45dc-4ad4-a729-1d35fb59052c.png)
<br/>

>Ao aparecer a tela de import selecione o notebook anteriormente baixado e prossiga na importa√ß√£o

![img3](https://user-images.githubusercontent.com/22823453/154808496-23055679-8bf7-4c2a-a791-6c84d4a22922.png)
<br/>

### Subindo dados

>Ao carregar o notebook clique no drop down responsavel pela fun√ß√£o Upload Data, selecione os arquivos anteriormente extraidos e prossiga na importa√ß√£o

![img4](https://user-images.githubusercontent.com/22823453/154808559-9178f322-8a68-4cc8-ab6a-b048e15995fa.png)
<br/>

>Fa√ßa o upload dos arquivos 

![img5](https://user-images.githubusercontent.com/22823453/154808563-0740acb0-cc86-49b5-95f1-f0d2f162fbd8.png)
<br/>

### ‚ñ∂ Executando!

>Inicie a execu√ß√£o de todas as celulas e pronto!

![img6](https://user-images.githubusercontent.com/22823453/154808570-dc8a9ac9-3b3f-44bf-89db-bb5ec9624b92.png)
<br/>

>Obs: O cluster necess√°rio para rodar a aplica√ß√£o ser√° criado automaticamente caso voc√™ n√£o tenha selecionado algum j√° existente previamente (opcional para fins did√°ticos).

<br/>

## ‚òï Organiza√ß√£o do desenvolvimento...

### A estrutura que foi criada segue o seguinte padr√£o.

<hr/>

* Cria√ß√£o do banco de dados

* Cria√ß√£o dos Dataframes a partir dos cvs

<hr/>

* Cra√ß√£o de tabela e tabela auxiliar

* Populando tabela auxiliar com respectivo Dataframe

* Populando tabela com tabela auxiliar com dados tratados

<hr/>

* Querys...
<hr/>

> Obs: O relacionamento entre tabelas √© feito apenas de forma conceitual, pois n√£o √© possivel definir chaves primarias eestrangeiras no Spark SQL
<br/>

![image](https://user-images.githubusercontent.com/22823453/154786708-b7a22c9e-368e-42fd-be88-97c6d889751f.png)

<br/>

## üìù Tratamentos dos dados

>Segue os principais dados que foram tratados

* Tipagem das colunas
* Adicionar valor "NULL" para o padr√£o null do Spark
* trocar "," por "."

[‚¨Ü Voltar ao topo](#nome-do-projeto)<br>
